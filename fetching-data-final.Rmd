
#Install All Packages
```{r}
install.packages("ROAuth")
install.packages("twitteR")
install.packages("slam")
install.packages("tm")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("topicmodels")
install.packages("syuzhet")
install.packages("tidyverse")

```


##Access to Twitter by My Developer's account
```{r}
library(ROAuth)
library(twitteR)

api_key <- "C4xwHq2EdZ5GL6LaNA6norgUd"

api_secret <- "1UJ4HDznWwTexLmzfu87GyQ01I41D9qugg9pJTwcKUubyZOpvp"

access_token <- "2497530812-8KAYKTo99IuY3bxNPvhARncRr8Eo2GL17GNoeaW"

access_token_secret <- "MXsEF7690Jg1u5S2aN7yLNQwFZKO7CcvizTMZcKBkGmya"

setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)

```


##Fetch Data from Twitter by Keyword "From: Amplify" and "@Amplify"
```{r}
Start_day <- as.character(Sys.Date() - 7)

End_day <- as.character(Sys.Date())

TL1 <- searchTwitter("@amplify", lang = "en", n=1000, since= Start_day, until= End_day)
TL1 <- do.call("rbind", lapply(TL1, as.data.frame))

TL2 <- searchTwitter("from:amplify", lang = "en", n=1000, since= Start_day, until= End_day)
TL2 <- do.call("rbind", lapply(TL2, as.data.frame))


write.csv(TL1,"amplify_@_tweets_10_22.csv")
write.csv(TL2,"amplify_from_tweets_10_22.csv")

library(dplyr)

df1 <- select(TL1, text, screenName, favoriteCount, retweetCount) 
df2 <- select(TL2, text, screenName, favoriteCount, retweetCount) 

colnames(df1) <- c("Tweet", "User", "Like","Forward")
colnames(df2) <- c("Tweet", "User", "Like","Forward")
```


##Visualization 1 - Sentiment Score Based on Tweets @Amplify
```{r}
library(RCurl)
library(tm)
library(wordcloud)
library(SnowballC)

DF1 <- select(df1, Tweet)

DF1$Tweet <- gsub("<.*?>", "", df1$Tweet)
DF1$Tweet <- gsub ("nbsp","", df1$Tweet)
DF1$Tweet <- gsub ("nbspnbspnbsp","",df1$Tweet)


#Convert the data frame to the corpus format that the tm package uses
corpus <- Corpus(VectorSource(DF1$Tweet))
 
#Remove spaces
corpus <- tm_map(corpus, stripWhitespace)
 
#Convert to lower case
corpus <- tm_map(corpus, tolower)
 
#Remove pre-defined stop words ('the', 'a', etc)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
 
#Convert words to stems ("education" = "edu") for analysis
corpus <- tm_map(corpus, stemDocument)
 
#Remove numbers
corpus <- tm_map(corpus, removeNumbers)
 
#remove punctuation
corpus <- tm_map(corpus, removePunctuation)

#Convert to plain text for mapping by wordcloud package
corpus <- tm_map(corpus, PlainTextDocument, lazy = TRUE)

corpus <- Corpus(VectorSource(corpus))
#Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(corpus, 
                                 control=list(removePunctuation = TRUE,
                                 stopwords = TRUE))
                      
library(syuzhet)
library(tidyverse)

#graphic code
#emotions <- get_nrc_sentiment(corpus$content)
#barplot (colSums(emotions), cex.names = 0.7, 
         #col = rainbow(10), main = "Sentiment Scores for Tweets")


#ggplot code
mysentiment <- get_nrc_sentiment(corpus$content)

SentimentScores <- data.frame(colSums(mysentiment[,]))

names(SentimentScores) <- "Score"

SentimentScores <- cbind ("sentiment" = rownames(SentimentScores), SentimentScores)

rownames(SentimentScores) <- NULL
  
ggplot(data = SentimentScores, aes(x = sentiment, y = Score)) +
  geom_bar(aes(fill = sentiment), stat = "identity") +
  theme (legend.position = "none") +
  xlab("Sentiment") + ylab ("Score") +
  ggtitle("Total Sentiment Score Based on Tweets @Amplify") +
  theme(plot.title = element_text(hjust = 0.5))

```


##Get all Paticipants and Followers
```{r}

#active_participants
participants <- lookupUsers(df1$User)
participants_df <- twListToDF(participants) %>%
  rownames_to_column()

#followers
user <- getUser("amplify")
followers <- user$getFollowers()
followers_df <- twListToDF(followers) %>%
  rownames_to_column()


```

##Visualization 2 -   Mapping out Distribution of Participants and Followers 
```{r}
follower_locations <- data.frame(followers_df$location)

participant_locations <- data.frame(participants_df$location)

# need to figure out how to plot the dots on a map

```

##Visualization 3 - Learn More about the Audience --> World Cloud on Profile Descriptions
```{r}

#followers' profile descriptions

DF2 <- select(followers_df, description)

DF2$Tweet <- gsub("<.*?>", "", followers_df$description)
DF2$Tweet <- gsub ("nbsp","", followers_df$description)
DF2$Tweet <- gsub ("nbspnbspnbsp","",followers_df$description)


#Convert the data frame to the corpus format that the tm package uses
corpus <- Corpus(VectorSource(DF2$Tweet))
 
#Remove spaces
corpus <- tm_map(corpus, stripWhitespace)
 
#Convert to lower case
corpus <- tm_map(corpus, tolower)
 
#Remove pre-defined stop words ('the', 'a', etc)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
 
#Convert words to stems ("education" = "edu") for analysis
corpus <- tm_map(corpus, stemDocument)

 
#Remove numbers
corpus <- tm_map(corpus, removeNumbers)
 
#remove punctuation
corpus <- tm_map(corpus, removePunctuation)

#Convert to plain text for mapping by wordcloud package
corpus <- tm_map(corpus, PlainTextDocument, lazy = TRUE)

corpus <- Corpus(VectorSource(corpus))
#Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(corpus, 
                                 control=list(removePunctuation = TRUE,
                                 stopwords = TRUE))
                      
#tdm.corpus <- TermDocumentMatrix(corpus)

col = brewer.pal(8, "Dark2")


wordcloud(corpus, random.order = F, min.freq = 200, max.word = 50, scale = c(4, 0.5),random.color = T, colors = col)

```
```{r}
#participants' profile descriptions

DF3 <- select(participants_df, description)

DF3$Tweet <- gsub("<.*?>", "", participants_df$description)
DF3$Tweet <- gsub ("nbsp","", participants_df$description)
DF3$Tweet <- gsub ("nbspnbspnbsp","",participants_df$description)


#Convert the data frame to the corpus format that the tm package uses
corpus <- Corpus(VectorSource(DF3$Tweet))
 
#Remove spaces
corpus <- tm_map(corpus, stripWhitespace)
 
#Convert to lower case
corpus <- tm_map(corpus, tolower)
 
#Remove pre-defined stop words ('the', 'a', etc)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
 
#Convert words to stems ("education" = "edu") for analysis
corpus <- tm_map(corpus, stemDocument)

 
#Remove numbers
corpus <- tm_map(corpus, removeNumbers)
 
#remove punctuation
corpus <- tm_map(corpus, removePunctuation)

#Convert to plain text for mapping by wordcloud package
corpus <- tm_map(corpus, PlainTextDocument, lazy = TRUE)

corpus <- Corpus(VectorSource(corpus))
#Convert corpus to a term document matrix - so each word can be analyzed individuallly
tdm.corpus <- TermDocumentMatrix(corpus, 
                                 control=list(removePunctuation = TRUE,
                                 stopwords = TRUE))
                      
#tdm.corpus <- TermDocumentMatrix(corpus)

col = brewer.pal(8, "Dark2")


wordcloud(corpus, random.order = F, min.freq = 200, max.word = 50, scale = c(4, 0.5),random.color = T, colors = col)

```
##Visualization 4 - Identify a List of VIP Influencers from Paticipants and Followers
```{r}

#identify top 30 participants who have the most followers
famous_participants <- participants_df %>%
  mutate(date = as.Date(created, format = "%Y-%m-%d"),
         today = as.Date("2018-10-22", format = "%Y-%m-%d"),
         days = as.numeric(today - date),
         statusesCount_pDay = statusesCount / days) %>%
  select(screenName, followersCount, statusesCount_pDay) %>%
  arrange(desc(followersCount)) %>%
  .[1:30, ]

#identify top 30 participants who tweet frequently
frequent_tweet_participants <- participants_df %>%
  mutate(date = as.Date(created, format = "%Y-%m-%d"),
         today = as.Date("2018-10-22", format = "%Y-%m-%d"),
         days = as.numeric(today - date),
         statusesCount_pDay = statusesCount / days) %>%
  select(screenName, followersCount, statusesCount_pDay) %>%
  arrange(desc(statusesCount_pDay)) %>%
  .[1:30, ]

VIP_participants <- rbind(famous_participants, frequent_tweet_participants) %>%
  unique()

#identify top 100 participants who have the most followers
famous_followers <- followers_df %>%
  mutate(date = as.Date(created, format = "%Y-%m-%d"),
         today = as.Date("2018-10-22", format = "%Y-%m-%d"),
         days = as.numeric(today - date),
         statusesCount_pDay = statusesCount / days) %>%
  select(screenName, followersCount, statusesCount_pDay) %>%
  arrange(desc(followersCount)) %>%
  .[1:100, ]

#identify top 100 participants who tweet frequently
frequent_tweet_followers <- followers_df %>%
  mutate(date = as.Date(created, format = "%Y-%m-%d"),
         today = as.Date("2018-10-22", format = "%Y-%m-%d"),
         days = as.numeric(today - date),
         statusesCount_pDay = statusesCount / days) %>%
  select(screenName, followersCount, statusesCount_pDay) %>%
  arrange(desc(statusesCount_pDay)) %>%
  .[1:100, ]

VIP_followers <- rbind(famous_followers, frequent_tweet_followers) %>%
  unique()

VIP_total <-  rbind(VIP_participants, VIP_followers) %>%
  unique() %>% arrange(desc(followersCount)) 

```
